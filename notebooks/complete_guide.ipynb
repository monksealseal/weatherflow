{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WeatherFlow: Complete Guide\n",
        "\n",
        "This notebook provides a comprehensive guide to using the WeatherFlow package with real weather data. It demonstrates:\n",
        "\n",
        "1. Loading and preprocessing ERA5 reanalysis data\n",
        "2. Training flow matching models on weather data\n",
        "3. Making predictions with trained models\n",
        "4. Visualizing and evaluating results\n",
        "5. Advanced techniques and customizations\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's set up our environment and import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Add repository root to Python path if running locally\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Get absolute path to repo root\n",
        "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "repo_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
        "\n",
        "# Add to path if not already there\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)\n",
        "    print(f\"Added {repo_root} to Python path\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Standard imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For geographic visualization\n",
        "try:\n",
        "    import cartopy.crs as ccrs\n",
        "    import cartopy.feature as cfeature\n",
        "    CARTOPY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Cartopy not available. Some visualizations will be limited.\")\n",
        "    CARTOPY_AVAILABLE = False\n",
        "\n",
        "# Set plot style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['figure.dpi'] = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import WeatherFlow package\n",
        "import weatherflow\n",
        "from weatherflow.data import ERA5Dataset, create_data_loaders\n",
        "from weatherflow.models import WeatherFlowMatch, WeatherFlowODE\n",
        "from weatherflow.training import FlowTrainer\n",
        "from weatherflow.utils import WeatherVisualizer, FlowVisualizer\n",
        "\n",
        "print(f\"WeatherFlow version: {weatherflow.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Loading and Exploring ERA5 Data\n",
        "\n",
        "ERA5 is a comprehensive reanalysis dataset from the European Centre for Medium-Range Weather Forecasts (ECMWF). It provides hourly estimates of atmospheric, land, and oceanic climate variables. We'll use the WeatherBench 2 version of ERA5 data for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Define parameters for data loading\n",
        "variables = ['z', 't']  # Geopotential height and temperature\n",
        "pressure_levels = [500]  # 500 hPa pressure level (mid-troposphere)\n",
        "time_slice = ('2016', '2017')  # 1-year period for the example\n",
        "\n",
        "try:\n",
        "    # Attempt to load the ERA5 dataset\n",
        "    dataset = ERA5Dataset(\n",
        "        variables=variables,\n",
        "        pressure_levels=pressure_levels,\n",
        "        time_slice=time_slice\n",
        "    )\n",
        "    \n",
        "    print(f\"Successfully loaded ERA5 data\")\n",
        "    print(f\"Dataset length: {len(dataset)} time steps\")\n",
        "    print(f\"Dataset shape: {dataset.shape}\")\n",
        "    \n",
        "    # Get a sample from the dataset\n",
        "    sample = dataset[0]\n",
        "    print(f\"\\nSample structure:\")\n",
        "    for key, value in sample.items():\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            print(f\"{key}: {value.shape}\")\n",
        "        else:\n",
        "            print(f\"{key}: {type(value)}\")\n",
        "    \n",
        "    data_available = True\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error loading ERA5 data: {str(e)}\")\n",
        "    print(\"\\nUsing synthetic data instead...\")\n",
        "    \n",
        "    # Create synthetic dataset\n",
        "    class SyntheticERA5Dataset:\n",
        "        def __init__(self, variables, pressure_levels, time_slice):\n",
        "            self.variables = variables\n",
        "            self.pressure_levels = pressure_levels\n",
        "            self.n_lat, self.n_lon = 32, 64\n",
        "            self.time_steps = 100\n",
        "            print(f\"Created synthetic dataset with {len(variables)} variables, {len(pressure_levels)} levels\")\n",
        "            \n",
        "        def __len__(self):\n",
        "            return self.time_steps - 1\n",
        "        \n",
        "        def __getitem__(self, idx):\n",
        "            # Create random tensors for input and target\n",
        "            input_data = torch.randn(len(self.variables), len(self.pressure_levels), self.n_lat, self.n_lon)\n",
        "            target_data = input_data + torch.randn_like(input_data) * 0.1  # Slightly perturbed for target\n",
        "            \n",
        "            return {\n",
        "                'input': input_data,\n",
        "                'target': target_data,\n",
        "                'metadata': {\n",
        "                    't0': '2016-01-01',\n",
        "                    't1': '2016-01-02',\n",
        "                    'variables': self.variables,\n",
        "                    'pressure_levels': self.pressure_levels\n",
        "                }\n",
        "            }\n",
        "        \n",
        "        @property\n",
        "        def shape(self):\n",
        "            return (len(self.variables), len(self.pressure_levels), self.n_lat, self.n_lon)\n",
        "    \n",
        "    dataset = SyntheticERA5Dataset(variables, pressure_levels, time_slice)\n",
        "    data_available = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing the data\n",
        "\n",
        "Let's examine our weather data by visualizing some samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create a visualizer\n",
        "visualizer = WeatherVisualizer()\n",
        "\n",
        "# Get a sample\n",
        "sample = dataset[0]\n",
        "input_data = sample['input']\n",
        "target_data = sample['target']\n",
        "\n",
        "# Create a figure to visualize the data\n",
        "fig, axes = plt.subplots(2, len(variables), figsize=(len(variables)*6, 10))\n",
        "\n",
        "# Plot each variable at the input time\n",
        "for i, var in enumerate(variables):\n",
        "    # Input data - first time step\n",
        "    if CARTOPY_AVAILABLE:\n",
        "        ax = plt.subplot(2, len(variables), i+1, projection=ccrs.Robinson())\n",
        "        visualizer.plot_weather_field(\n",
        "            data=input_data[i, 0].numpy(),  # First pressure level\n",
        "            ax=ax,\n",
        "            title=f\"{var} (Input)\",\n",
        "            colorbar=True,\n",
        "            projection=ccrs.Robinson()\n",
        "        )\n",
        "    else:\n",
        "        ax = plt.subplot(2, len(variables), i+1)\n",
        "        im = ax.imshow(input_data[i, 0].numpy(), cmap='viridis')\n",
        "        plt.colorbar(im, ax=ax)\n",
        "        ax.set_title(f\"{var} (Input)\")\n",
        "    \n",
        "    # Target data - next time step\n",
        "    if CARTOPY_AVAILABLE:\n",
        "        ax = plt.subplot(2, len(variables), i+1+len(variables), projection=ccrs.Robinson())\n",
        "        visualizer.plot_weather_field(\n",
        "            data=target_data[i, 0].numpy(),  # First pressure level\n",
        "            ax=ax,\n",
        "            title=f\"{var} (Target)\",\n",
        "            colorbar=True,\n",
        "            projection=ccrs.Robinson()\n",
        "        )\n",
        "    else:\n",
        "        ax = plt.subplot(2, len(variables), i+1+len(variables))\n",
        "        im = ax.imshow(target_data[i, 0].numpy(), cmap='viridis')\n",
        "        plt.colorbar(im, ax=ax)\n",
        "        ax.set_title(f\"{var} (Target)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Creating Data Loaders\n",
        "\n",
        "Now we'll create data loaders for training and validation sets, which handle the batching and other preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create data loaders\n",
        "batch_size = 8\n",
        "\n",
        "if hasattr(dataset, 'ds') and hasattr(dataset, 'times'):\n",
        "    # Using real ERA5 data\n",
        "    try:\n",
        "        # Split into train and validation sets (80/20)\n",
        "        train_size = int(0.8 * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        \n",
        "        from torch.utils.data import random_split, DataLoader\n",
        "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "        \n",
        "        print(f\"Created data loaders with {train_size} training and {val_size} validation samples\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating data loaders: {str(e)}\")\n",
        "        # Use weatherflow's built-in function\n",
        "        train_loader, val_loader = create_data_loaders(\n",
        "            variables=variables,\n",
        "            pressure_levels=pressure_levels,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "else:\n",
        "    # Using synthetic data\n",
        "    from torch.utils.data import random_split, DataLoader\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    \n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    \n",
        "    print(f\"Created data loaders with {train_size} training and {val_size} validation samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check a batch from the data loader to see if everything is working correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Get a batch from the train loader\n",
        "batch = next(iter(train_loader))\n",
        "\n",
        "# Print batch information\n",
        "print(\"Batch structure:\")\n",
        "for key, value in batch.items():\n",
        "    if isinstance(value, torch.Tensor):\n",
        "        print(f\"{key}: {value.shape}\")\n",
        "    else:\n",
        "        print(f\"{key}: {type(value)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Creating and Training the Model\n",
        "\n",
        "Now we'll create a WeatherFlowMatch model, which implements flow matching for weather prediction, and train it on our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Set up device (use GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create the model\n",
        "model = WeatherFlowMatch(\n",
        "    input_channels=len(variables),\n",
        "    hidden_dim=128,  # Smaller for this example\n",
        "    n_layers=3,      # Fewer layers for faster training\n",
        "    use_attention=True,\n",
        "    physics_informed=True\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = FlowTrainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    scheduler=scheduler,\n",
        "    physics_regularization=True,\n",
        "    physics_lambda=0.1\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model created with {total_params:,} parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Define number of epochs for training\n",
        "num_epochs = 5  # Small for this example\n",
        "\n",
        "# Store metrics for plotting\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    \n",
        "    # Train for one epoch\n",
        "    train_metrics = trainer.train_epoch(train_loader)\n",
        "    train_loss = train_metrics['loss']\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    # Validate\n",
        "    val_metrics = trainer.validate(val_loader)\n",
        "    val_loss = val_metrics['val_loss']\n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    # Update scheduler\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # Print metrics\n",
        "    print(f\"Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
        "    \n",
        "    # Save best model (in a real scenario, you'd save to disk)\n",
        "    if epoch == 0 or val_loss < min(val_losses[:-1]):\n",
        "        best_model_state = model.state_dict()\n",
        "        print(\"New best model!\")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Load best model (in a real scenario, you'd load from disk)\n",
        "model.load_state_dict(best_model_state)\n",
        "print(\"Loaded best model!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Making Predictions with the Model\n",
        "\n",
        "Now that we have a trained model, we can use it to make predictions. We'll wrap our flow matching model with the WeatherFlowODE class, which integrates the learned velocity field to generate predictions at specific time points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create ODE model for prediction\n",
        "ode_model = WeatherFlowODE(\n",
        "    flow_model=model,\n",
        "    solver_method='rk4',  # Runge-Kutta 4 (faster than dopri5 for this example)\n",
        "    rtol=1e-3,\n",
        "    atol=1e-3\n",
        ")\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Get a batch from validation set\n",
        "val_batch = next(iter(val_loader))\n",
        "x0 = val_batch['input'].to(device)\n",
        "x1_true = val_batch['target'].to(device)\n",
        "\n",
        "# Define prediction times (0 = start, 1 = end)\n",
        "times = torch.linspace(0, 1, 5).to(device)  # Generate 5 time steps\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    try:\n",
        "        predictions = ode_model(x0, times)\n",
        "        print(f\"Generated predictions with shape: {predictions.shape}\")\n",
        "        prediction_ok = True\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating predictions: {str(e)}\")\n",
        "        print(\"Using simple linear interpolation instead...\")\n",
        "        \n",
        "        # Simple linear interpolation as fallback\n",
        "        predictions = []\n",
        "        for t in times:\n",
        "            t_val = t.item()\n",
        "            pred_t = x0 * (1 - t_val) + x1_true * t_val\n",
        "            predictions.append(pred_t)\n",
        "        predictions = torch.stack(predictions)\n",
        "        print(f\"Generated predictions with shape: {predictions.shape}\")\n",
        "        prediction_ok = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualizing Predictions\n",
        "\n",
        "Now let's visualize our predictions to see how the weather evolves over time according to our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Select a sample from the batch to visualize (first one)\n",
        "sample_idx = 0\n",
        "\n",
        "# Setup visualization\n",
        "num_timesteps = len(times)\n",
        "var_idx = 0  # First variable (e.g., geopotential)\n",
        "level_idx = 0  # First pressure level\n",
        "\n",
        "# Create a figure\n",
        "fig, axes = plt.subplots(1, num_timesteps, figsize=(4*num_timesteps, 4))\n",
        "\n",
        "# Plot each time step\n",
        "for i, t in enumerate(times):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # Get prediction at this time step\n",
        "    pred = predictions[i, sample_idx, var_idx, level_idx].cpu().numpy()\n",
        "    \n",
        "    # Plot\n",
        "    im = ax.imshow(pred, cmap='viridis')\n",
        "    ax.set_title(f\"t={t.item():.2f}\")\n",
        "    ax.axis('off')\n",
        "    \n",
        "    # Add colorbar to the last plot\n",
        "    if i == num_timesteps - 1:\n",
        "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "plt.suptitle(f\"Evolution of {variables[var_idx]} at {pressure_levels[level_idx]} hPa\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Compare the final prediction with the ground truth\n",
        "for var_idx, var_name in enumerate(variables):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    # Initial state\n",
        "    x0_np = x0[sample_idx, var_idx, level_idx].cpu().numpy()\n",
        "    im0 = axes[0].imshow(x0_np, cmap='viridis')\n",
        "    axes[0].set_title(f\"Initial {var_name}\")\n",
        "    plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Final prediction\n",
        "    x1_pred_np = predictions[-1, sample_idx, var_idx, level_idx].cpu().numpy()\n",
        "    im1 = axes[1].imshow(x1_pred_np, cmap='viridis')\n",
        "    axes[1].set_title(f\"Predicted {var_name}\")\n",
        "    plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    # Ground truth\n",
        "    x1_true_np = x1_true[sample_idx, var_idx, level_idx].cpu().numpy()\n",
        "    im2 = axes[2].imshow(x1_true_np, cmap='viridis')\n",
        "    axes[2].set_title(f\"Ground Truth {var_name}\")\n",
        "    plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.suptitle(f\"{var_name} at {pressure_levels[level_idx]} hPa\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Calculate error metrics\n",
        "    mse = ((x1_pred_np - x1_true_np) ** 2).mean()\n",
        "    mae = np.abs(x1_pred_np - x1_true_np).mean()\n",
        "    \n",
        "    print(f\"{var_name} Metrics:\")\n",
        "    print(f\"MSE: {mse:.6f}\")\n",
        "    print(f\"MAE: {mae:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analyzing Model Behavior\n",
        "\n",
        "Let's analyze how our model behaves as we vary certain parameters, like the time parameter in the flow model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Select a sample input\n",
        "x_sample = x0[sample_idx:sample_idx+1]\n",
        "\n",
        "# Try different time values\n",
        "time_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "velocities = []\n",
        "\n",
        "# Compute the velocity field for each time value\n",
        "with torch.no_grad():\n",
        "    for t in time_values:\n",
        "        t_tensor = torch.tensor([t], device=device)\n",
        "        v = model(x_sample, t_tensor)\n",
        "        velocities.append(v.cpu())\n",
        "\n",
        "# Visualize the velocity field for the first variable\n",
        "var_idx = 0\n",
        "level_idx = 0\n",
        "\n",
        "fig, axes = plt.subplots(1, len(time_values), figsize=(4*len(time_values), 4))\n",
        "\n",
        "for i, (t, v) in enumerate(zip(time_values, velocities)):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # Get velocity at this time step\n",
        "    v_field = v[0, var_idx, level_idx].numpy()\n",
        "    \n",
        "    # Plot\n",
        "    im = ax.imshow(v_field, cmap='coolwarm')\n",
        "    ax.set_title(f\"t={t:.2f}\")\n",
        "    ax.axis('off')\n",
        "    \n",
        "    # Add colorbar to the last plot\n",
        "    if i == len(time_values) - 1:\n",
        "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "plt.suptitle(f\"Velocity Field for {variables[var_idx]} at Different Times\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Advanced Visualization - Flow Field\n",
        "\n",
        "Let's visualize the flow field of our model to better understand the predicted weather dynamics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Initialize flow visualizer\n",
        "flow_vis = FlowVisualizer()\n",
        "\n",
        "# Check if we have multiple variables for vector field visualization\n",
        "if len(variables) >= 2:\n",
        "    # Compute the flow at t=0.5\n",
        "    t_mid = torch.tensor([0.5], device=device)\n",
        "    with torch.no_grad():\n",
        "        v_mid = model(x_sample, t_mid).cpu()[0]\n",
        "    \n",
        "    # Extract u, v components (first two variables)\n",
        "    u = v_mid[0, level_idx].numpy()\n",
        "    v = v_mid[1, level_idx].numpy()\n",
        "    \n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    if CARTOPY_AVAILABLE:\n",
        "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "        ax.coastlines()\n",
        "        \n",
        "        # Downsample for clearer visualization\n",
        "        stride = 2\n",
        "        lats = np.linspace(-90, 90, u.shape[0])[::stride]\n",
        "        lons = np.linspace(-180, 180, u.shape[1])[::stride]\n",
        "        \n",
        "        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
        "        \n",
        "        # Plot flow vectors\n",
        "        ax.quiver(lon_grid, lat_grid, \n",
        "                 u[::stride, ::stride], v[::stride, ::stride],\n",
        "                 scale=50, width=0.002)\n",
        "        \n",
        "        # Add gridlines and background\n",
        "        ax.gridlines(draw_labels=True)\n",
        "        ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "        ax.add_feature(cfeature.COASTLINE)\n",
        "        \n",
        "        plt.title(f\"Flow Field at t=0.5\")\n",
        "    else:\n",
        "        # Simple vector field plot without cartopy\n",
        "        y, x = np.mgrid[0:u.shape[0]:5, 0:u.shape[1]:5]\n",
        "        plt.quiver(x, y, u[::5, ::5], v[::5, ::5])\n",
        "        plt.title(f\"Flow Field at t=0.5 (u={variables[0]}, v={variables[1]})\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Need at least two variables for vector field visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Making Multi-step Predictions\n",
        "\n",
        "Let's use our model to make multi-step predictions (forecasting several days ahead)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Function to make multi-step predictions\n",
        "def multi_step_predict(model, x0, n_steps=3):\n",
        "    \"\"\"Make multi-step predictions using the flow model.\"\"\"\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    # Initial state\n",
        "    x = x0.clone()\n",
        "    predictions = [x]\n",
        "    \n",
        "    # Make predictions step by step\n",
        "    with torch.no_grad():\n",
        "        for step in range(n_steps):\n",
        "            try:\n",
        "                # Use ODE model for one step\n",
        "                times = torch.tensor([0.0, 1.0], device=x.device)\n",
        "                x_next = ode_model(x, times)[-1]  # Take the final state\n",
        "            except Exception as e:\n",
        "                # Fallback to direct prediction\n",
        "                t = torch.ones(x.size(0), device=x.device)\n",
        "                v = model(x, t)\n",
        "                x_next = x + v  # Simple Euler integration\n",
        "            \n",
        "            predictions.append(x_next)\n",
        "            x = x_next\n",
        "    \n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Make multi-step predictions\n",
        "n_steps = 3  # Predict 3 steps ahead\n",
        "multi_step_preds = multi_step_predict(model, x_sample, n_steps)\n",
        "\n",
        "# Visualize multi-step predictions\n",
        "var_idx = 0  # First variable\n",
        "level_idx = 0  # First pressure level\n",
        "\n",
        "fig, axes = plt.subplots(1, n_steps+1, figsize=(4*(n_steps+1), 4))\n",
        "\n",
        "for i, pred in enumerate(multi_step_preds):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # Get prediction\n",
        "    pred_np = pred[0, var_idx, level_idx].cpu().numpy()\n",
        "    \n",
        "    # Plot\n",
        "    im = ax.imshow(pred_np, cmap='viridis')\n",
        "    ax.set_title(f\"Step {i}\")\n",
        "    ax.axis('off')\n",
        "    \n",
        "    # Add colorbar to the last plot\n",
        "    if i == n_steps:\n",
        "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "plt.suptitle(f\"Multi-step Prediction of {variables[var_idx]} at {pressure_levels[level_idx]} hPa\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Creating an Animation\n",
        "\n",
        "Let's create an animation to visualize the flow dynamics more clearly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Try to create an animation (if the environment supports it)\n",
        "try:\n",
        "    from matplotlib.animation import FuncAnimation\n",
        "    from IPython.display import HTML\n",
        "    \n",
        "    # Generate more dense predictions for smoother animation\n",
        "    times = torch.linspace(0, 1, 20).to(device)  # 20 time steps\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            dense_preds = ode_model(x_sample, times)\n",
        "            animation_data = dense_preds[:, 0, var_idx, level_idx].cpu().numpy()\n",
        "        except Exception as e:\n",
        "            # Fallback to simple interpolation\n",
        "            print(f\"Using simple interpolation for animation\")\n",
        "            animation_data = []\n",
        "            x_start = x_sample[0, var_idx, level_idx].cpu().numpy()\n",
        "            x_end = x1_true[sample_idx, var_idx, level_idx].cpu().numpy()\n",
        "            \n",
        "            for t in times:\n",
        "                t_val = t.item()\n",
        "                frame = x_start * (1 - t_val) + x_end * t_val\n",
        "                animation_data.append(frame)\n",
        "            animation_data = np.array(animation_data)\n",
        "    \n",
        "    # Create figure for animation\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    plt.close()  # Close the figure to prevent display\n",
        "    \n",
        "    # Find global min/max for consistent colorbar\n",
        "    vmin = animation_data.min()\n",
        "    vmax = animation_data.max()\n",
        "    \n",
        "    # Initial plot\n",
        "    im = ax.imshow(animation_data[0], cmap='viridis', vmin=vmin, vmax=vmax)\n",
        "    title = ax.set_title(f\"{variables[var_idx]} at t=0.00\")\n",
        "    plt.colorbar(im, ax=ax)\n",
        "    \n",
        "    # Animation update function\n",
        "    def update(frame):\n",
        "        im.set_array(animation_data[frame])\n",
        "        title.set_text(f\"{variables[var_idx]} at t={times[frame].item():.2f}\")\n",
        "        return [im, title]\n",
        "    \n",
        "    # Create animation\n",
        "    anim = FuncAnimation(fig, update, frames=len(animation_data), interval=200, blit=True)\n",
        "    \n",
        "    # Display in notebook\n",
        "    HTML(anim.to_jshtml())\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Could not create animation: {str(e)}\")\n",
        "    print(\"Try running this notebook in an environment with animation support.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Conclusion and Next Steps\n",
        "\n",
        "In this notebook, we've demonstrated the complete workflow for using the WeatherFlow package:\n",
        "\n",
        "1. Loading and exploring ERA5 reanalysis data\n",
        "2. Creating data loaders for training and validation\n",
        "3. Building and training a flow matching model\n",
        "4. Making predictions using the trained model\n",
        "5. Visualizing and analyzing the results\n",
        "6. Creating advanced visualizations and animations\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "To build on what we've learned:\n",
        "\n",
        "1. **Try different variables**: Experiment with other atmospheric variables like humidity or winds.\n",
        "2. **Modify model architecture**: Adjust the number of layers, hidden dimensions, or try without attention.\n",
        "3. **Experiment with physics constraints**: Toggle physics-informed constraints and see how they affect results.\n",
        "4. **Train for longer**: Increase the number of epochs for better convergence.\n",
        "5. **Evaluate on test data**: Use a separate test set to evaluate model performance.\n",
        "6. **Compare with other methods**: Try simple baselines or other prediction models for comparison.\n",
        "\n",
        "For more information, refer to the WeatherFlow documentation and examples."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}